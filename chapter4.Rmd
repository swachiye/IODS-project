---
title: "Clustering and classification"
author: "Sheila"
date: "18/11/2020"
output: html_document
---
**Load data **

Boston dataset contains data about housing in the area of Boston Mass as collected by the U.S Census Service.
```{r}
# Access MASS library 
library(MASS)

# Load Boston data
data("Boston")
```

```{r}
# explore Boston dataset
str(Boston)
dim(Boston)
```
The Boston dataset has has 506 rows and 14 columns. 

The summary of the dataset
```{r}
summary(Boston)

# plot matrix of the variables
pairs(Boston)

```


We can assess the correlations between variables with correlation matrix plot:

```{r}
library(corrplot)
library(tidyverse)

# First calculate the correlation matrix 
corr_matrix<-cor(Boston)%>% round(2)

# print corr_matrix
corr_matrix

# visualize the correlation matrix
corrplot(corr_matrix, method="circle", type = "upper", tl.cex = 1.2) %>% round(2)
```

Correlation Matrices
Correlation of target variable with predictor variables:

1. crim are highly correlated to indu, nox, age, rad, and tax and Istat and negatively to zn, rm,dis and medv
2. rm and lstat are highly correlated with the target variable medv
3. black, dis, rm, chas, zn are positively correlated with medv
4. crim, indus, nox, age, rad, tax, ptratio, lstat are negatively correlated with medv


** Data standardization**

The fact that Boston data contains only numerical values, we can use the function *scale()* to standardize the whole dataset.

```{r}
# center and standardize variables using scale()
boston_scaled <- scale(Boston)

# summaries of the scaled variables
summary(boston_scaled)

# check the class of the boston_scaled object
class(boston_scaled)

# change the object to data frame
boston_scaled <- as.data.frame(boston_scaled)
```

Create a categorical variable of the crime rate in the Boston dataset (from the scaled crime rate).

```{r}
# First create a quantile vector of crim 
bins <- quantile(boston_scaled$crim)


# create a categorical variable 'crime'
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label=c("low", "med_low", "med_high", "high")) 
```


Drop the old crime rate variable from the dataset.

```{r}
# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim) %>% round(2)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)

#print
boston_scaled 
```


 Divide the dataset to train and test sets, so that 80% of the data belongs to the train set.
```{r}
# Get the number of rows in the Boston dataset and assign it as *n* 
n <- nrow(boston_scaled)

# Select randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)

# Use the selected to create train set
train_data <- boston_scaled[ind,]
train_data
# create test set 
test_data  <- boston_scaled[-ind,]

# save the correct classes from test data
correct_classes <- test_data$crime

# remove the crime variable from test data
test_data <- dplyr::select(test, -crime)
test_data
```

**Linear Discriminant analysis**

```{r}

# linear discriminant analysis
# the dot means all other variables in the data.
lda.fit <- lda(crime ~ ., data = train_data) 

# print the lda.fit object
lda.fit 

```


Draw the LDA (bi)plot.

```{r}
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 2)
```



